# Aula 1: Instala√ß√£o Local do Apache Spark
Este guia cobre a instala√ß√£o do Apache Spark localmente em Windows, macOS e Linux. Siga os passos conforme o sistema operacional que voc√™ utiliza.

## Pr√©-requisitos
  - Java 8 ou 11: O Spark precisa do Java instalado.
  - Python 3.6 ou superior: Para compatibilidade com o PySpark.
  - Terminal: Prompt de Comando (Windows) ou Terminal (macOS/Linux).

## ü™ü - Windows
#### Passo 1: Instalar o Java
1- Baixe o OpenJDK 11 do site do AdoptOpenJDK (.msi installer).

2- Execute o instalador.

3- Configure a vari√°vel de ambiente `JAVA_HOME`:
  - Abra ‚ÄúEditar vari√°veis de ambiente do sistema‚Äù no Menu Iniciar.
  - Adicione uma nova vari√°vel de sistema:
    - Nome: `JAVA_HOME`
    - Valor: `C:\Program Files\AdoptOpenJDK\jdk-11.0.11.9-hotspot` (ajuste o caminho conforme necess√°rio).
  - Edite a vari√°vel `Path` e adicione: `%JAVA_HOME%\bin`
    
4- Verifique: Abra um novo Prompt de Comando e execute `java -version`.

#### Passo 2: Instalar o Python
1- Baixe o Python 3.6+ em [python.org](python.org).

2- Execute o instalador e marque a op√ß√£o **‚ÄúAdd Python to PATH‚Äù**.

3- Verifique: Execute `python --version` em um novo Prompt de Comando.

#### Passo 3: Instalar o Spark
1- Baixe o Spark 3.5.5 (Hadoop 3.x) de [spark.apache.org](spark.apache.org) (arquivo `.tgz`).

2- Extraia o conte√∫do para `C:\spark-3.5.5-bin-hadoop3` usando o 7-Zip.

3- Configure a vari√°vel de ambiente `SPARK_HOME`:
  - Nome: `SPARK_HOME`
  - Valor: `C:\spark-3.5.5-bin-hadoop3`
  - Edite o `Path` e adicione: `%SPARK_HOME%\bin`

4- Instale o `winutils`:
  - Baixe o `winutils.exe` compat√≠vel com Hadoop 3.x [neste reposit√≥rio GitHub](https://github.com/steveloughran/winutils).
  - Coloque o arquivo em `C:\hadoop\bin`.
  - Adicione a vari√°vel:
    - Nome: `HADOOP_HOME`
    - Valor: `C:\hadoop`
    - Adicione `%HADOOP_HOME%\bin` ao `Path`.

#### Passo 4: Verificar
Abra um novo Prompt de Comando e execute:
````bash
spark-shell
````
Voc√™ deve ver o logo do Spark. Para sair, digite `:q`.









## üçé - MacOS
#### Passo 1: Instalar o Java
1. Instale o Homebrew (caso ainda n√£o tenha):
````bash
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
````

2. Execute:
````bash
brew install openjdk@11
````

3- Configure o `JAVA_HOME`:

Adicione no seu `~/.zshrc` ou `~/.bash_profile`:
````bash
export JAVA_HOME=$(/usr/libexec/java_home -v 11)
````
Depois, execute:
````bash
source ~/.zshrc
````
Verifique com:
````bash
java -version
````

#### Passo 2: Instalar o Python
````bash
brew install python
````

Verifique com:
````bash
python3 --version
````

#### Passo 3: Instalar o Spark
Op√ß√£o 1 ‚Äì via Homebrew:
````bash
brew install apache-spark
````
(Op√ß√£o r√°pida que instala a vers√£o mais recente)

Op√ß√£o 2 ‚Äì Manual:

1- Baixe o Spark 3.5.5 (Hadoop 3.x) de spark.apache.org.

2- Extraia:
````bash
tar -xzf spark-3.5.5-bin-hadoop3.tgz
````

3- Mova para o diret√≥rio:
````bash
sudo mv spark-3.5.5-bin-hadoop3 /usr/local/spark-3.5.5-bin-hadoop3
````

4- Adicione no `~/.zshrc`:
````bash
export SPARK_HOME=/usr/local/spark-3.5.5-bin-hadoop3
export PATH=$SPARK_HOME/bin:$PATH
````

5- Execute:
````bash
source ~/.zshrc
````

#### Passo 4: Verificar
Execute no terminal:
````bash
spark-shell
````

Procure pelo logo do Spark. Saia com `:q`.












## üêß - Linux (Ubuntu / Debian-based)
#### Passo 1: Instalar o Java
````bash
sudo apt update
sudo apt install openjdk-11-jdk
````

Configure o `JAVA_HOME`:

Adicione ao `~/.bashrc`:
````bash
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export PATH=$JAVA_HOME/bin:$PATH
````

Depois, execute:
````bash
source ~/.bashrc
````

Verifique com:
````bash
java -version
````

#### Passo 2: Instalar o Python
````bash
sudo apt install python3 python3-pip
````

Verifique:
````bash
python3 --version
````

#### Passo 3: Instalar o Spark
````bash
wget https://downloads.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz
tar -xzf spark-3.5.5-bin-hadoop3.tgz
sudo mv spark-3.5.5-bin-hadoop3 /opt/spark
````

Configure as vari√°veis de ambiente:

Adicione ao `~/.bashrc`:
````bash
export SPARK_HOME=/opt/spark
export PATH=$SPARK_HOME/bin:$PATH
````

Depois, execute:
````bash
source ~/.bashrc
````

#### Passo 4: Verificar
Execute:
````bash
spark-shell
````

O logo do Spark deve aparecer. Para sair, digite `:q`.













